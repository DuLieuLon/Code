{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import pickle, string, re\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import *\n",
    "from keras.preprocessing.sequence import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalText(sent):\n",
    "    sent = str(sent).replace('_',' ').replace('/',' trÃªn ')\n",
    "    sent = re.sub('-{2,}','',sent)\n",
    "    sent = re.sub('\\\\s+',' ', sent)\n",
    "    patPrice = r'([0-9]+k?(\\s?-\\s?)[0-9]+\\s?(k|K))|([0-9]+(.|,)?[0-9]+\\s?(triá»‡u|ngÃ n|trÄƒm|k|K|))|([0-9]+(.[0-9]+)?Ã„â€˜)|([0-9]+k)'\n",
    "    patURL = r\"(?:http://|www.)[^\\\"]+\"\n",
    "    sent = re.sub(patURL,'website',sent)\n",
    "    sent = re.sub(patPrice, ' giÃ¡_tiá»n ', sent)\n",
    "    sent = re.sub('\\.+','.',sent)\n",
    "    sent = re.sub('(hagtag\\\\s+)+',' hagtag ',sent)\n",
    "    sent = re.sub('\\\\s+',' ',sent)\n",
    "    return sent\n",
    "\n",
    "def deleteIcon(text):\n",
    "    text = text.lower()\n",
    "    s = ''\n",
    "    pattern = r\"[a-zA-ZaÄƒÃ¢bcdÄ‘eÃªghiklmnoÃ´Æ¡pqrstuÆ°vxyÃ áº±áº§bcdÄ‘Ã¨á»ghÃ¬klmnÃ²á»“á»pqrstÃ¹á»«vxá»³Ã¡áº¯áº¥bcdÄ‘Ã©áº¿ghÃ­klmnÃ³á»‘á»›pqrstÃºá»©vxÃ½áº£áº³áº©bcdÄ‘áº»á»ƒghá»‰klmná»á»•á»Ÿpqrstá»§á»­vxá»·áº¡áº·áº­bcdÄ‘áº¹á»‡ghá»‹klmná»á»™á»£pqrstá»¥á»±vxá»µÃ£áºµáº«bcdÄ‘áº½á»…ghÄ©klmnÃµá»—á»¡pqrstÅ©á»¯vxá»¹AÄ‚Ã‚BCDÄEÃŠGHIKLMNOÃ”Æ PQRSTUÆ¯VXYÃ€áº°áº¦BCDÄÃˆá»€GHÃŒKLMNÃ’á»’á»œPQRSTÃ™á»ªVXá»²Ãáº®áº¤BCDÄÃ‰áº¾GHÃKLMNÃ“á»á»šPQRSTÃšá»¨VXÃáº áº¶áº¬BCDÄáº¸á»†GHá»ŠKLMNá»Œá»˜á»¢PQRSTá»¤á»°VXá»´áº¢áº²áº¨BCDÄáººá»‚GHá»ˆKLMNá»á»”á»PQRSTá»¦á»¬VXá»¶Ãƒáº´áºªBCDÄáº¼á»„GHÄ¨KLMNÃ•á»–á» PQRSTÅ¨á»®VXá»¸,._]\"\n",
    "    \n",
    "    for char in text:\n",
    "        if char !=' ':\n",
    "            if len(re.findall(pattern, char)) != 0:\n",
    "                s+=char\n",
    "            elif char == '_':\n",
    "                s+=char\n",
    "        else:\n",
    "            s+=char\n",
    "    s = re.sub('\\\\s+',' ',s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def clean_doc(doc):\n",
    "    for punc in string.punctuation:\n",
    "        doc = doc.replace(punc,' '+ punc + ' ')\n",
    "    doc = normalText(doc)\n",
    "    doc = deleteIcon(doc)\n",
    "    doc = ViTokenizer.tokenize(doc)\n",
    "    doc = doc.lower()\n",
    "    doc = re.sub(r\"\\?\", \" \\? \", doc)\n",
    "    doc = re.sub(r\"[0-9]+\", \" num \", doc)\n",
    "    for punc in string.punctuation:\n",
    "        if punc not in \"_\":\n",
    "            doc = doc.replace(punc,' ')\n",
    "    doc = re.sub('\\\\s+',' ',doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save ='model/'\n",
    "model = load_model(path_save + 'ResCNN_model.h5')\n",
    "\n",
    "with open('model/input_tokenizer.pkl', 'rb') as fp:\n",
    "    input_tokenizer = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLength = 548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Äáº§u vÃ o:  MÃ¹a Ä‘Ã´ng rá»“i cÃ²n gÃ¬ tuyá»‡t vá»i hÆ¡n lÃ  Äƒn á»‘c vá»›i Äƒn ngao ğŸ˜ - Nguyá»…n Khiáº¿t lÃ  ngÃµ cáº¯t ngang PhÃºc TÃ¢n áº¥y cÃ¡c báº¡n áº¡. Chá»— mÃ  nhiá»u nhiá»u hÃ ng karaoke. - Ä‚n á»Ÿ Ä‘Ã¢y thÃ¬ hÆ¡i xa má»™t chÃºt nhÆ°ng Ã´ii thÃ´i ngon thÃ´i rá»“i Ä‘áº£m báº£o khÃ´ng máº¥t cÃ´ng lÃªn Ä‘Ã¢y Äƒn Ä‘Ã¢u. - GiÃ¡ chá»‰ 30k-40k cho 1 bÃ¡t ngao háº¥p Ä‘áº§y Ãº á»¥ luÃ´n ğŸ’“- Chá»— nhÆ° áº£nh mÃ¬nh Äƒn háº¿t cÃ³ 100k huhu mÃ  2 ng Äƒn no cháº¿t Ä‘i Ä‘c. Coca cÃ³ 5k 1 chai trÃ  Ä‘Ã¡ thÃ¬ free luÃ´n nhÃ© cÃ¡c báº¡n ğŸ˜ - BÃ¡c chá»§ quÃ¡n hiá»n láº¯m luÃ´n Ã½. Nhiá»u lÃºc mÃ¬nh gá»i nhiá»u Äƒn cháº£ háº¿t xong bÃ¡c Ã½ cÃ²n cháº£ láº¥y tiá»n cÆ¡ ğŸ˜­ğŸ˜©\n",
      "Dá»± Ä‘oÃ¡n:  {FOOD#STYLE&OPTIONS, positive}, {FOOD#PRICES, positive}, {FOOD#QUALITY, positive}, {SERVICE#GENERAL, positive}, \n"
     ]
    }
   ],
   "source": [
    "input_text = \"MÃ¹a Ä‘Ã´ng rá»“i cÃ²n gÃ¬ tuyá»‡t vá»i hÆ¡n lÃ  Äƒn á»‘c vá»›i Äƒn ngao ğŸ˜ - Nguyá»…n Khiáº¿t lÃ  ngÃµ cáº¯t ngang PhÃºc TÃ¢n áº¥y cÃ¡c báº¡n áº¡. Chá»— mÃ  nhiá»u nhiá»u hÃ ng karaoke. - Ä‚n á»Ÿ Ä‘Ã¢y thÃ¬ hÆ¡i xa má»™t chÃºt nhÆ°ng Ã´ii thÃ´i ngon thÃ´i rá»“i Ä‘áº£m báº£o khÃ´ng máº¥t cÃ´ng lÃªn Ä‘Ã¢y Äƒn Ä‘Ã¢u. - GiÃ¡ chá»‰ 30k-40k cho 1 bÃ¡t ngao háº¥p Ä‘áº§y Ãº á»¥ luÃ´n ğŸ’“- Chá»— nhÆ° áº£nh mÃ¬nh Äƒn háº¿t cÃ³ 100k huhu mÃ  2 ng Äƒn no cháº¿t Ä‘i Ä‘c. Coca cÃ³ 5k 1 chai trÃ  Ä‘Ã¡ thÃ¬ free luÃ´n nhÃ© cÃ¡c báº¡n ğŸ˜ - BÃ¡c chá»§ quÃ¡n hiá»n láº¯m luÃ´n Ã½. Nhiá»u lÃºc mÃ¬nh gá»i nhiá»u Äƒn cháº£ háº¿t xong bÃ¡c Ã½ cÃ²n cháº£ láº¥y tiá»n cÆ¡ ğŸ˜­ğŸ˜©\"\n",
    "input_clean = clean_doc(input_text)\n",
    "input_index = np.array(pad_sequences(input_tokenizer.texts_to_sequences([input_clean]), maxlen=maxLength,padding=\"post\"))\n",
    "\n",
    "listLabel = 'FOOD#STYLE&OPTIONS,FOOD#PRICES,FOOD#QUALITY,DRINKS#STYLE&OPTIONS,DRINKS#QUALITY,DRINKS#PRICES,RESTAURANT#GENERAL,RESTAURANT#MISCELLANEOUS,RESTAURANT#PRICES,LOCATION#GENERAL,SERVICE#GENERAL,AMBIENCE#GENERAL'\n",
    "categories = listLabel.split(',')\n",
    "\n",
    "predicted = model.predict([np.expand_dims(input_index[0], axis=0)])\n",
    "output = ''\n",
    "for i, predict in enumerate(predicted):\n",
    "    index2, value = max(enumerate(predict[0]), key=operator.itemgetter(1))\n",
    "    if index2 == 1:\n",
    "        output+= '{' + str(categories[i]) + ', positive}, '\n",
    "    elif index2 == 2:\n",
    "        output+= '{' + str(categories[i]) + ', neutral}, '\n",
    "    elif index2 == 3:\n",
    "        output+= '{' + str(categories[i]) + ', negative}, '\n",
    "print(\"Äáº§u vÃ o: \", input_text)\n",
    "print(\"Dá»± Ä‘oÃ¡n: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
